/**
 * $Id: sh4x86.in,v 1.3 2007-09-04 08:40:23 nkeynes Exp $
 * 
 * SH4 => x86 translation. This version does no real optimization, it just
 * outputs straight-line x86 code - it mainly exists to provide a baseline
 * to test the optimizing versions against.
 *
 * Copyright (c) 2007 Nathan Keynes.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#include <assert.h>

#include "sh4/sh4core.h"
#include "sh4/sh4trans.h"
#include "sh4/x86op.h"
#include "clock.h"

#define DEFAULT_BACKPATCH_SIZE 4096

/** 
 * Struct to manage internal translation state. This state is not saved -
 * it is only valid between calls to sh4_translate_begin_block() and
 * sh4_translate_end_block()
 */
struct sh4_x86_state {
    gboolean in_delay_slot;
    gboolean priv_checked; /* true if we've already checked the cpu mode. */
    gboolean fpuen_checked; /* true if we've already checked fpu enabled. */

    /* Allocated memory for the (block-wide) back-patch list */
    uint32_t **backpatch_list;
    uint32_t backpatch_posn;
    uint32_t backpatch_size;
};

#define EXIT_DATA_ADDR_READ 0
#define EXIT_DATA_ADDR_WRITE 7
#define EXIT_ILLEGAL 14
#define EXIT_SLOT_ILLEGAL 21
#define EXIT_FPU_DISABLED 28
#define EXIT_SLOT_FPU_DISABLED 35

static struct sh4_x86_state sh4_x86;

void sh4_x86_init()
{
    sh4_x86.backpatch_list = malloc(DEFAULT_BACKPATCH_SIZE);
    sh4_x86.backpatch_size = DEFAULT_BACKPATCH_SIZE / sizeof(uint32_t *);
}


static void sh4_x86_add_backpatch( uint8_t *ptr )
{
    if( sh4_x86.backpatch_posn == sh4_x86.backpatch_size ) {
	sh4_x86.backpatch_size <<= 1;
	sh4_x86.backpatch_list = realloc( sh4_x86.backpatch_list, sh4_x86.backpatch_size * sizeof(uint32_t *) );
	assert( sh4_x86.backpatch_list != NULL );
    }
    sh4_x86.backpatch_list[sh4_x86.backpatch_posn++] = (uint32_t *)ptr;
}

static void sh4_x86_do_backpatch( uint8_t *reloc_base )
{
    unsigned int i;
    for( i=0; i<sh4_x86.backpatch_posn; i++ ) {
	*sh4_x86.backpatch_list[i] += (reloc_base - ((uint8_t *)sh4_x86.backpatch_list[i]));
    }
}

#ifndef NDEBUG
#define MARK_JMP(x,n) uint8_t *_mark_jmp_##x = xlat_output + n
#define CHECK_JMP(x) assert( _mark_jmp_##x == xlat_output )
#else
#define MARK_JMP(x,n)
#define CHECK_JMP(x)
#endif


/**
 * Emit an instruction to load an SH4 reg into a real register
 */
static inline void load_reg( int x86reg, int sh4reg ) 
{
    /* mov [bp+n], reg */
    OP(0x8B);
    OP(0x45 + (x86reg<<3));
    OP(REG_OFFSET(r[sh4reg]));
}

/**
 * Load the SR register into an x86 register
 */
static inline void read_sr( int x86reg )
{
    MOV_ebp_r32( R_M, x86reg );
    SHL1_r32( x86reg );
    OR_ebp_r32( R_Q, x86reg );
    SHL_imm8_r32( 7, x86reg );
    OR_ebp_r32( R_S, x86reg );
    SHL1_r32( x86reg );
    OR_ebp_r32( R_T, x86reg );
    OR_ebp_r32( R_SR, x86reg );
}

static inline void write_sr( int x86reg )
{
    TEST_imm32_r32( SR_M, x86reg );
    SETNE_ebp(R_M);
    TEST_imm32_r32( SR_Q, x86reg );
    SETNE_ebp(R_Q);
    TEST_imm32_r32( SR_S, x86reg );
    SETNE_ebp(R_S);
    TEST_imm32_r32( SR_T, x86reg );
    SETNE_ebp(R_T);
    AND_imm32_r32( SR_MQSTMASK, x86reg );
    MOV_r32_ebp( x86reg, R_SR );
}
    

static inline void load_spreg( int x86reg, int regoffset )
{
    /* mov [bp+n], reg */
    OP(0x8B);
    OP(0x45 + (x86reg<<3));
    OP(regoffset);
}

/**
 * Emit an instruction to load an immediate value into a register
 */
static inline void load_imm32( int x86reg, uint32_t value ) {
    /* mov #value, reg */
    OP(0xB8 + x86reg);
    OP32(value);
}

/**
 * Emit an instruction to store an SH4 reg (RN)
 */
void static inline store_reg( int x86reg, int sh4reg ) {
    /* mov reg, [bp+n] */
    OP(0x89);
    OP(0x45 + (x86reg<<3));
    OP(REG_OFFSET(r[sh4reg]));
}
void static inline store_spreg( int x86reg, int regoffset ) {
    /* mov reg, [bp+n] */
    OP(0x89);
    OP(0x45 + (x86reg<<3));
    OP(regoffset);
}

/**
 * Note: clobbers EAX to make the indirect call - this isn't usually
 * a problem since the callee will usually clobber it anyway.
 */
static inline void call_func0( void *ptr )
{
    load_imm32(R_EAX, (uint32_t)ptr);
    CALL_r32(R_EAX);
}

static inline void call_func1( void *ptr, int arg1 )
{
    PUSH_r32(arg1);
    call_func0(ptr);
    ADD_imm8s_r32( -4, R_ESP );
}

static inline void call_func2( void *ptr, int arg1, int arg2 )
{
    PUSH_r32(arg2);
    PUSH_r32(arg1);
    call_func0(ptr);
    ADD_imm8s_r32( -4, R_ESP );
}

/* Exception checks - Note that all exception checks will clobber EAX */
static void check_priv( )
{
    if( !sh4_x86.priv_checked ) {
	sh4_x86.priv_checked = TRUE;
	load_spreg( R_EAX, R_SR );
	AND_imm32_r32( SR_MD, R_EAX );
	if( sh4_x86.in_delay_slot ) {
	    JE_exit( EXIT_SLOT_ILLEGAL );
	} else {
	    JE_exit( EXIT_ILLEGAL );
	}
    }
}

static void check_fpuen( )
{
    if( !sh4_x86.fpuen_checked ) {
	sh4_x86.fpuen_checked = TRUE;
	load_spreg( R_EAX, R_SR );
	AND_imm32_r32( SR_FD, R_EAX );
	if( sh4_x86.in_delay_slot ) {
	    JNE_exit(EXIT_SLOT_FPU_DISABLED);
	} else {
	    JNE_exit(EXIT_FPU_DISABLED);
	}
    }
}

static void check_ralign16( int x86reg )
{
    TEST_imm32_r32( 0x00000001, x86reg );
    JNE_exit(EXIT_DATA_ADDR_READ);
}

static void check_walign16( int x86reg )
{
    TEST_imm32_r32( 0x00000001, x86reg );
    JNE_exit(EXIT_DATA_ADDR_WRITE);
}

static void check_ralign32( int x86reg )
{
    TEST_imm32_r32( 0x00000003, x86reg );
    JNE_exit(EXIT_DATA_ADDR_READ);
}
static void check_walign32( int x86reg )
{
    TEST_imm32_r32( 0x00000003, x86reg );
    JNE_exit(EXIT_DATA_ADDR_WRITE);
}


#define UNDEF()
#define MEM_RESULT(value_reg) if(value_reg != R_EAX) { MOV_r32_r32(R_EAX,value_reg); }
#define MEM_READ_BYTE( addr_reg, value_reg ) call_func1(sh4_read_byte, addr_reg ); MEM_RESULT(value_reg)
#define MEM_READ_WORD( addr_reg, value_reg ) call_func1(sh4_read_word, addr_reg ); MEM_RESULT(value_reg)
#define MEM_READ_LONG( addr_reg, value_reg ) call_func1(sh4_read_long, addr_reg ); MEM_RESULT(value_reg)
#define MEM_WRITE_BYTE( addr_reg, value_reg ) call_func2(sh4_write_byte, addr_reg, value_reg)
#define MEM_WRITE_WORD( addr_reg, value_reg ) call_func2(sh4_write_word, addr_reg, value_reg)
#define MEM_WRITE_LONG( addr_reg, value_reg ) call_func2(sh4_write_long, addr_reg, value_reg)

#define RAISE_EXCEPTION( exc ) call_func1(sh4_raise_exception, exc);
#define CHECKSLOTILLEGAL() if(sh4_x86.in_delay_slot) RAISE_EXCEPTION(EXC_SLOT_ILLEGAL)



/**
 * Emit the 'start of block' assembly. Sets up the stack frame and save
 * SI/DI as required
 */
void sh4_translate_begin_block() 
{
    PUSH_r32(R_EBP);
    PUSH_r32(R_ESI);
    /* mov &sh4r, ebp */
    load_imm32( R_EBP, (uint32_t)&sh4r );
    PUSH_r32(R_ESI);
    
    sh4_x86.in_delay_slot = FALSE;
    sh4_x86.priv_checked = FALSE;
    sh4_x86.fpuen_checked = FALSE;
    sh4_x86.backpatch_posn = 0;
}

/**
 * Exit the block early (ie branch out), conditionally or otherwise
 */
void exit_block( uint32_t pc )
{
    load_imm32( R_ECX, pc );
    store_spreg( R_ECX, REG_OFFSET(pc) );
    MOV_moff32_EAX( (uint32_t)&sh4_cpu_period );
    load_spreg( R_ECX, REG_OFFSET(slice_cycle) );
    MUL_r32( R_ESI );
    ADD_r32_r32( R_EAX, R_ECX );
    store_spreg( R_ECX, REG_OFFSET(slice_cycle) );
    XOR_r32_r32( R_EAX, R_EAX );
    RET();
}

/**
 * Flush any open regs back to memory, restore SI/DI/, update PC, etc
 */
void sh4_translate_end_block( sh4addr_t pc ) {
    assert( !sh4_x86.in_delay_slot ); // should never stop here
    // Normal termination - save PC, cycle count
    exit_block( pc );

    uint8_t *end_ptr = xlat_output;
    // Exception termination. Jump block for various exception codes:
    PUSH_imm32( EXC_DATA_ADDR_READ );
    JMP_rel8( 33 );
    PUSH_imm32( EXC_DATA_ADDR_WRITE );
    JMP_rel8( 26 );
    PUSH_imm32( EXC_ILLEGAL );
    JMP_rel8( 19 );
    PUSH_imm32( EXC_SLOT_ILLEGAL ); 
    JMP_rel8( 12 );
    PUSH_imm32( EXC_FPU_DISABLED ); 
    JMP_rel8( 5 );                 
    PUSH_imm32( EXC_SLOT_FPU_DISABLED );
    // target
    load_spreg( R_ECX, REG_OFFSET(pc) );
    ADD_r32_r32( R_ESI, R_ECX );
    ADD_r32_r32( R_ESI, R_ECX );
    store_spreg( R_ECX, REG_OFFSET(pc) );
    MOV_moff32_EAX( (uint32_t)&sh4_cpu_period );
    load_spreg( R_ECX, REG_OFFSET(slice_cycle) );
    MUL_r32( R_ESI );
    ADD_r32_r32( R_EAX, R_ECX );
    store_spreg( R_ECX, REG_OFFSET(slice_cycle) );

    load_imm32( R_EAX, (uint32_t)sh4_raise_exception ); // 6
    CALL_r32( R_EAX ); // 2
    POP_r32(R_EBP);
    RET();

    sh4_x86_do_backpatch( end_ptr );
}

/**
 * Translate a single instruction. Delayed branches are handled specially
 * by translating both branch and delayed instruction as a single unit (as
 * 
 *
 * @return true if the instruction marks the end of a basic block
 * (eg a branch or 
 */
uint32_t sh4_x86_translate_instruction( uint32_t pc )
{
    uint16_t ir = sh4_read_word( pc );
    
%%
/* ALU operations */
ADD Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
ADD #imm, Rn {:  
    load_reg( R_EAX, Rn );
    ADD_imm8s_r32( imm, R_EAX );
    store_reg( R_EAX, Rn );
:}
ADDC Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    LDC_t();
    ADC_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETC_t();
:}
ADDV Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETO_t();
:}
AND Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    AND_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
AND #imm, R0 {:  
    load_reg( R_EAX, 0 );
    AND_imm32_r32(imm, R_EAX); 
    store_reg( R_EAX, 0 );
:}
AND.B #imm, @(R0, GBR) {: 
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_r32_r32( R_EAX, R_EBX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    AND_imm32_r32(imm, R_ECX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
CMP/EQ Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETE_t();
:}
CMP/EQ #imm, R0 {:  
    load_reg( R_EAX, 0 );
    CMP_imm8s_r32(imm, R_EAX);
    SETE_t();
:}
CMP/GE Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETGE_t();
:}
CMP/GT Rm, Rn {: 
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETG_t();
:}
CMP/HI Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETA_t();
:}
CMP/HS Rm, Rn {: 
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETAE_t();
 :}
CMP/PL Rn {: 
    load_reg( R_EAX, Rn );
    CMP_imm8s_r32( 0, R_EAX );
    SETG_t();
:}
CMP/PZ Rn {:  
    load_reg( R_EAX, Rn );
    CMP_imm8s_r32( 0, R_EAX );
    SETGE_t();
:}
CMP/STR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    XOR_r32_r32( R_ECX, R_EAX );
    TEST_r8_r8( R_AL, R_AL );
    JE_rel8(13);
    TEST_r8_r8( R_AH, R_AH ); // 2
    JE_rel8(9);
    SHR_imm8_r32( 16, R_EAX ); // 3
    TEST_r8_r8( R_AL, R_AL ); // 2
    JE_rel8(2);
    TEST_r8_r8( R_AH, R_AH ); // 2
    SETE_t();
:}
DIV0S Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rm );
    SHR_imm8_r32( 31, R_EAX );
    SHR_imm8_r32( 31, R_ECX );
    store_spreg( R_EAX, R_M );
    store_spreg( R_ECX, R_Q );
    CMP_r32_r32( R_EAX, R_ECX );
    SETE_t();
:}
DIV0U {:  
    XOR_r32_r32( R_EAX, R_EAX );
    store_spreg( R_EAX, R_Q );
    store_spreg( R_EAX, R_M );
    store_spreg( R_EAX, R_T );
:}
DIV1 Rm, Rn {:  :}
DMULS.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    IMUL_r32(R_ECX);
    store_spreg( R_EDX, R_MACH );
    store_spreg( R_EAX, R_MACL );
:}
DMULU.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MUL_r32(R_ECX);
    store_spreg( R_EDX, R_MACH );
    store_spreg( R_EAX, R_MACL );    
:}
DT Rn {:  
    load_reg( R_EAX, Rn );
    ADD_imm8s_r32( -1, Rn );
    store_reg( R_EAX, Rn );
    SETE_t();
:}
EXTS.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVSX_r8_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTS.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVSX_r16_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTU.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVZX_r8_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTU.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVZX_r16_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MAC.L @Rm+, @Rn+ {:  :}
MAC.W @Rm+, @Rn+ {:  :}
MOVT Rn {:  
    load_spreg( R_EAX, R_T );
    store_reg( R_EAX, Rn );
:}
MUL.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MUL_r32( R_ECX );
    store_spreg( R_EAX, R_MACL );
:}
MULS.W Rm, Rn {:  
:}
MULU.W Rm, Rn {:  :}
NEG Rm, Rn {:
    load_reg( R_EAX, Rm );
    NEG_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
NEGC Rm, Rn {:  
    load_reg( R_EAX, Rm );
    XOR_r32_r32( R_ECX, R_ECX );
    LDC_t();
    SBB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETC_t();
:}
NOT Rm, Rn {:  
    load_reg( R_EAX, Rm );
    NOT_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
OR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
OR #imm, R0 {:
    load_reg( R_EAX, 0 );
    OR_imm32_r32(imm, R_EAX);
    store_reg( R_EAX, 0 );
:}
OR.B #imm, @(R0, GBR) {:  :}
ROTCL Rn {:
    load_reg( R_EAX, Rn );
    LDC_t();
    RCL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
:}
ROTCR Rn {:  
    load_reg( R_EAX, Rn );
    LDC_t();
    RCR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
:}
ROTL Rn {:  
    load_reg( R_EAX, Rn );
    ROL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
:}
ROTR Rn {:  
    load_reg( R_EAX, Rn );
    ROR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
:}
SHAD Rm, Rn {:
    /* Annoyingly enough, not directly convertible */
    load_reg( R_EAX, Rn );
    load_reg( R_ECX, Rm );
    CMP_imm32_r32( 0, R_ECX );
    JAE_rel8(9);
                    
    NEG_r32( R_ECX );      // 2
    AND_imm8_r8( 0x1F, R_CL ); // 3
    SAR_r32_CL( R_EAX );       // 2
    JMP_rel8(5);               // 2
    
    AND_imm8_r8( 0x1F, R_CL ); // 3
    SHL_r32_CL( R_EAX );       // 2
                    
    store_reg( R_EAX, Rn );
:}
SHLD Rm, Rn {:  
    load_reg( R_EAX, Rn );
    load_reg( R_ECX, Rm );

    MOV_r32_r32( R_EAX, R_EDX );
    SHL_r32_CL( R_EAX );
    NEG_r32( R_ECX );
    SHR_r32_CL( R_EDX );
    CMP_imm8s_r32( 0, R_ECX );
    CMOVAE_r32_r32( R_EDX,  R_EAX );
    store_reg( R_EAX, Rn );
:}
SHAL Rn {: 
    load_reg( R_EAX, Rn );
    SHL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
SHAR Rn {:  
    load_reg( R_EAX, Rn );
    SAR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLL Rn {:  
    load_reg( R_EAX, Rn );
    SHL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLL2 Rn {:
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 2, R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLL8 Rn {:  
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 8, R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLL16 Rn {:  
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 16, R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLR Rn {:  
    load_reg( R_EAX, Rn );
    SHR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLR2 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 2, R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLR8 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 8, R_EAX );
    store_reg( R_EAX, Rn );
:}
SHLR16 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 16, R_EAX );
    store_reg( R_EAX, Rn );
:}
SUB Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SUB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
SUBC Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    LDC_t();
    SBB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
SUBV Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SUB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETO_t();
:}
SWAP.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    XCHG_r8_r8( R_AL, R_AH );
    store_reg( R_EAX, Rn );
:}
SWAP.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    SHL_imm8_r32( 16, R_ECX );
    SHR_imm8_r32( 16, R_EAX );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
TAS.B @Rn {:  
    load_reg( R_ECX, Rn );
    MEM_READ_BYTE( R_ECX, R_EAX );
    TEST_r8_r8( R_AL, R_AL );
    SETE_t();
    OR_imm8_r8( 0x80, R_AL );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
TST Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    TEST_r32_r32( R_EAX, R_ECX );
    SETE_t();
:}
TST #imm, R0 {:  
    load_reg( R_EAX, 0 );
    TEST_imm32_r32( imm, R_EAX );
    SETE_t();
:}
TST.B #imm, @(R0, GBR) {:  
    load_reg( R_EAX, 0);
    load_reg( R_ECX, R_GBR);
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    TEST_imm8_r8( imm, R_EAX );
    SETE_t();
:}
XOR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    XOR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}
XOR #imm, R0 {:  
    load_reg( R_EAX, 0 );
    XOR_imm32_r32( imm, R_EAX );
    store_reg( R_EAX, 0 );
:}
XOR.B #imm, @(R0, GBR) {:  
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    XOR_imm32_r32( imm, R_EAX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
XTRCT Rm, Rn {:
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    SHR_imm8_r32( 16, R_EAX );
    SHL_imm8_r32( 16, R_ECX );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
:}

/* Data move instructions */
MOV Rm, Rn {:  
    load_reg( R_EAX, Rm );
    store_reg( R_EAX, Rn );
:}
MOV #imm, Rn {:  
    load_imm32( R_EAX, imm );
    store_reg( R_EAX, Rn );
:}
MOV.B Rm, @Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
MOV.B Rm, @-Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -1, Rn );
    store_reg( R_ECX, Rn );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
MOV.B Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
MOV.B R0, @(disp, GBR) {:  
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
MOV.B R0, @(disp, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
:}
MOV.B @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_ECX, Rn );
:}
MOV.B @Rm+, Rn {:  
    load_reg( R_ECX, Rm );
    MOV_r32_r32( R_ECX, R_EAX );
    ADD_imm8s_r32( 1, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.B @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.B @(disp, GBR), R0 {:  
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOV.B @(disp, Rm), R0 {:  
    load_reg( R_ECX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOV.L Rm, @Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
MOV.L Rm, @-Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
MOV.L Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
MOV.L R0, @(disp, GBR) {:  
    load_spreg( R_ECX, R_GBR );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
MOV.L Rm, @(disp, Rn) {:  
    load_reg( R_ECX, Rn );
    load_reg( R_EAX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
MOV.L @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.L @Rm+, Rn {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.L @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.L @(disp, GBR), R0 {:
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOV.L @(disp, PC), Rn {:  
    load_imm32( R_ECX, (pc & 0xFFFFFFFC) + disp + 4 );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOV.L @(disp, Rm), Rn {:  
    load_reg( R_ECX, Rm );
    ADD_imm8s_r32( disp, R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W Rm, @Rn {:  
    load_reg( R_ECX, Rn );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W Rm, @-Rn {:  
    load_reg( R_ECX, Rn );
    load_reg( R_EAX, Rm );
    ADD_imm8s_r32( -2, R_ECX );
    MEM_WRITE_WORD( R_ECX, R_EAX );
:}
MOV.W Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_WORD( R_ECX, R_EAX );
:}
MOV.W R0, @(disp, GBR) {:  
    load_spreg( R_ECX, R_GBR );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_WORD( R_ECX, R_EAX );
:}
MOV.W R0, @(disp, Rn) {:  
    load_reg( R_ECX, Rn );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_WORD( R_ECX, R_EAX );
:}
MOV.W @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W @Rm+, Rn {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 2, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W @(disp, GBR), R0 {:  
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOV.W @(disp, PC), Rn {:  
    load_imm32( R_ECX, pc + disp + 4 );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MOV.W @(disp, Rm), R0 {:  
    load_reg( R_ECX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
:}
MOVA @(disp, PC), R0 {:  
    load_imm32( R_ECX, (pc & 0xFFFFFFFC) + disp + 4 );
    store_reg( R_ECX, 0 );
:}
MOVCA.L R0, @Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}

/* Control transfer instructions */
BF disp {:  
    CMP_imm8s_ebp( 0, R_T );
    JNE_rel8( 1 );
    exit_block( disp + pc + 4 );
    return 1;
:}
BF/S disp {:  
    CMP_imm8s_ebp( 0, R_T );
    JNE_rel8( 1 );
    exit_block( disp + pc + 4 );
    sh4_x86.in_delay_slot = TRUE;
:}
BRA disp {:  
    exit_block( disp + pc + 4 );
:}
BRAF Rn {:  :}
BSR disp {:  :}
BSRF Rn {:  :}
BT disp {:  /* If true, result PC += 4 + disp. else result PC = pc+2 */
    return pc + 2;
:}
BT/S disp {:

    return pc + 4;
:}
JMP @Rn {:  :}
JSR @Rn {:  :}
RTE {:  :}
RTS {:  :}
TRAPA #imm {:  :}
UNDEF {:  :}

CLRMAC {:  :}
CLRS {:  :}
CLRT {:  :}
SETS {:  :}
SETT {:  :}

/* Floating point instructions */
FABS FRn {:  :}
FADD FRm, FRn {:  :}
FCMP/EQ FRm, FRn {:  :}
FCMP/GT FRm, FRn {:  :}
FCNVDS FRm, FPUL {:  :}
FCNVSD FPUL, FRn {:  :}
FDIV FRm, FRn {:  :}
FIPR FVm, FVn {:  :}
FLDS FRm, FPUL {:  :}
FLDI0 FRn {:  :}
FLDI1 FRn {:  :}
FLOAT FPUL, FRn {:  :}
FMAC FR0, FRm, FRn {:  :}
FMOV FRm, FRn {:  :}
FMOV FRm, @Rn {:  :}
FMOV FRm, @-Rn {:  :}
FMOV FRm, @(R0, Rn) {:  :}
FMOV @Rm, FRn {:  :}
FMOV @Rm+, FRn {:  :}
FMOV @(R0, Rm), FRn {:  :}
FMUL FRm, FRn {:  :}
FNEG FRn {:  :}
FRCHG {:  :}
FSCA FPUL, FRn {:  :}
FSCHG {:  :}
FSQRT FRn {:  :}
FSRRA FRn {:  :}
FSTS FPUL, FRn {:  :}
FSUB FRm, FRn {:  :}
FTRC FRm, FPUL {:  :}
FTRV XMTRX, FVn {:  :}

/* Processor control instructions */
LDC Rm, SR {:
    load_reg( R_EAX, Rm );
    write_sr( R_EAX );
:}
LDC Rm, GBR {: 
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_GBR );
:}
LDC Rm, VBR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_VBR );
:}
LDC Rm, SSR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SSR );
:}
LDC Rm, SGR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SGR );
:}
LDC Rm, SPC {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SPC );
:}
LDC Rm, DBR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_DBR );
:}
LDC Rm, Rn_BANK {:  :}
LDC.L @Rm+, GBR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_GBR );
:}
LDC.L @Rm+, SR {:
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    write_sr( R_EAX );
:}
LDC.L @Rm+, VBR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_VBR );
:}
LDC.L @Rm+, SSR {:
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SSR );
:}
LDC.L @Rm+, SGR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SGR );
:}
LDC.L @Rm+, SPC {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SPC );
:}
LDC.L @Rm+, DBR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_DBR );
:}
LDC.L @Rm+, Rn_BANK {:  
:}
LDS Rm, FPSCR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_FPSCR );
:}
LDS.L @Rm+, FPSCR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_FPSCR );
:}
LDS Rm, FPUL {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_FPUL );
:}
LDS.L @Rm+, FPUL {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_FPUL );
:}
LDS Rm, MACH {: 
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_MACH );
:}
LDS.L @Rm+, MACH {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_MACH );
:}
LDS Rm, MACL {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_MACL );
:}
LDS.L @Rm+, MACL {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_MACL );
:}
LDS Rm, PR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_PR );
:}
LDS.L @Rm+, PR {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_PR );
:}
LDTLB {:  :}
OCBI @Rn {:  :}
OCBP @Rn {:  :}
OCBWB @Rn {:  :}
PREF @Rn {:  :}
SLEEP {:  :}
 STC SR, Rn {:
     read_sr( R_EAX );
     store_reg( R_EAX, Rn );
:}
STC GBR, Rn {:  
    load_spreg( R_EAX, R_GBR );
    store_reg( R_EAX, Rn );
:}
STC VBR, Rn {:  
    load_spreg( R_EAX, R_VBR );
    store_reg( R_EAX, Rn );
:}
STC SSR, Rn {:  
    load_spreg( R_EAX, R_SSR );
    store_reg( R_EAX, Rn );
:}
STC SPC, Rn {:  
    load_spreg( R_EAX, R_SPC );
    store_reg( R_EAX, Rn );
:}
STC SGR, Rn {:  
    load_spreg( R_EAX, R_SGR );
    store_reg( R_EAX, Rn );
:}
STC DBR, Rn {:  
    load_spreg( R_EAX, R_DBR );
    store_reg( R_EAX, Rn );
:}
STC Rm_BANK, Rn {: /* TODO */ 
:}
STC.L SR, @-Rn {:  /* TODO */
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    read_sr( R_EAX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L VBR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_VBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L SSR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SSR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L SPC, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SPC );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L SGR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SGR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L DBR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_DBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STC.L Rm_BANK, @-Rn {:  :}
STC.L GBR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_GBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STS FPSCR, Rn {:  
    load_spreg( R_EAX, R_FPSCR );
    store_reg( R_EAX, Rn );
:}
STS.L FPSCR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_FPSCR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STS FPUL, Rn {:  
    load_spreg( R_EAX, R_FPUL );
    store_reg( R_EAX, Rn );
:}
STS.L FPUL, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_FPUL );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STS MACH, Rn {:  
    load_spreg( R_EAX, R_MACH );
    store_reg( R_EAX, Rn );
:}
STS.L MACH, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_MACH );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STS MACL, Rn {:  
    load_spreg( R_EAX, R_MACL );
    store_reg( R_EAX, Rn );
:}
STS.L MACL, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_MACL );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}
STS PR, Rn {:  
    load_spreg( R_EAX, R_PR );
    store_reg( R_EAX, Rn );
:}
STS.L PR, @-Rn {:  
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -4, Rn );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_PR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
:}

NOP {: /* Do nothing. Well, we could emit an 0x90, but what would really be the point? */ :}
%%
    INC_r32(R_ESI);

    return 0;
}
