/**
 * $Id: sh4x86.in,v 1.19 2007-10-04 08:47:27 nkeynes Exp $
 * 
 * SH4 => x86 translation. This version does no real optimization, it just
 * outputs straight-line x86 code - it mainly exists to provide a baseline
 * to test the optimizing versions against.
 *
 * Copyright (c) 2007 Nathan Keynes.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#include <assert.h>
#include <math.h>

#ifndef NDEBUG
#define DEBUG_JUMPS 1
#endif

#include "sh4/xltcache.h"
#include "sh4/sh4core.h"
#include "sh4/sh4trans.h"
#include "sh4/sh4mmio.h"
#include "sh4/x86op.h"
#include "clock.h"

#define DEFAULT_BACKPATCH_SIZE 4096

/** 
 * Struct to manage internal translation state. This state is not saved -
 * it is only valid between calls to sh4_translate_begin_block() and
 * sh4_translate_end_block()
 */
struct sh4_x86_state {
    gboolean in_delay_slot;
    gboolean priv_checked; /* true if we've already checked the cpu mode. */
    gboolean fpuen_checked; /* true if we've already checked fpu enabled. */
    gboolean branch_taken; /* true if we branched unconditionally */
    uint32_t block_start_pc;
    int tstate;

    /* Allocated memory for the (block-wide) back-patch list */
    uint32_t **backpatch_list;
    uint32_t backpatch_posn;
    uint32_t backpatch_size;
};

#define TSTATE_NONE -1
#define TSTATE_O    0
#define TSTATE_C    2
#define TSTATE_E    4
#define TSTATE_NE   5
#define TSTATE_G    0xF
#define TSTATE_GE   0xD
#define TSTATE_A    7
#define TSTATE_AE   3

/** Branch if T is set (either in the current cflags, or in sh4r.t) */
#define JT_rel8(rel8,label) if( sh4_x86.tstate == TSTATE_NONE ) { \
	CMP_imm8s_sh4r( 1, R_T ); sh4_x86.tstate = TSTATE_E; } \
    OP(0x70+sh4_x86.tstate); OP(rel8); \
    MARK_JMP(rel8,label)
/** Branch if T is clear (either in the current cflags or in sh4r.t) */
#define JF_rel8(rel8,label) if( sh4_x86.tstate == TSTATE_NONE ) { \
	CMP_imm8s_sh4r( 1, R_T ); sh4_x86.tstate = TSTATE_E; } \
    OP(0x70+ (sh4_x86.tstate^1)); OP(rel8); \
    MARK_JMP(rel8, label)


#define EXIT_DATA_ADDR_READ 0
#define EXIT_DATA_ADDR_WRITE 7
#define EXIT_ILLEGAL 14
#define EXIT_SLOT_ILLEGAL 21
#define EXIT_FPU_DISABLED 28
#define EXIT_SLOT_FPU_DISABLED 35

static struct sh4_x86_state sh4_x86;

static uint32_t max_int = 0x7FFFFFFF;
static uint32_t min_int = 0x80000000;
static uint32_t save_fcw; /* save value for fpu control word */
static uint32_t trunc_fcw = 0x0F7F; /* fcw value for truncation mode */

void sh4_x86_init()
{
    sh4_x86.backpatch_list = malloc(DEFAULT_BACKPATCH_SIZE);
    sh4_x86.backpatch_size = DEFAULT_BACKPATCH_SIZE / sizeof(uint32_t *);
}


static void sh4_x86_add_backpatch( uint8_t *ptr )
{
    if( sh4_x86.backpatch_posn == sh4_x86.backpatch_size ) {
	sh4_x86.backpatch_size <<= 1;
	sh4_x86.backpatch_list = realloc( sh4_x86.backpatch_list, sh4_x86.backpatch_size * sizeof(uint32_t *) );
	assert( sh4_x86.backpatch_list != NULL );
    }
    sh4_x86.backpatch_list[sh4_x86.backpatch_posn++] = (uint32_t *)ptr;
}

static void sh4_x86_do_backpatch( uint8_t *reloc_base )
{
    unsigned int i;
    for( i=0; i<sh4_x86.backpatch_posn; i++ ) {
	*sh4_x86.backpatch_list[i] += (reloc_base - ((uint8_t *)sh4_x86.backpatch_list[i]) - 4);
    }
}

/**
 * Emit an instruction to load an SH4 reg into a real register
 */
static inline void load_reg( int x86reg, int sh4reg ) 
{
    /* mov [bp+n], reg */
    OP(0x8B);
    OP(0x45 + (x86reg<<3));
    OP(REG_OFFSET(r[sh4reg]));
}

static inline void load_reg16s( int x86reg, int sh4reg )
{
    OP(0x0F);
    OP(0xBF);
    MODRM_r32_sh4r(x86reg, REG_OFFSET(r[sh4reg]));
}

static inline void load_reg16u( int x86reg, int sh4reg )
{
    OP(0x0F);
    OP(0xB7);
    MODRM_r32_sh4r(x86reg, REG_OFFSET(r[sh4reg]));

}

#define load_spreg( x86reg, regoff ) MOV_sh4r_r32( regoff, x86reg )
#define store_spreg( x86reg, regoff ) MOV_r32_sh4r( x86reg, regoff )
/**
 * Emit an instruction to load an immediate value into a register
 */
static inline void load_imm32( int x86reg, uint32_t value ) {
    /* mov #value, reg */
    OP(0xB8 + x86reg);
    OP32(value);
}

/**
 * Emit an instruction to store an SH4 reg (RN)
 */
void static inline store_reg( int x86reg, int sh4reg ) {
    /* mov reg, [bp+n] */
    OP(0x89);
    OP(0x45 + (x86reg<<3));
    OP(REG_OFFSET(r[sh4reg]));
}

#define load_fr_bank(bankreg) load_spreg( bankreg, REG_OFFSET(fr_bank))

/**
 * Load an FR register (single-precision floating point) into an integer x86
 * register (eg for register-to-register moves)
 */
void static inline load_fr( int bankreg, int x86reg, int frm )
{
    OP(0x8B); OP(0x40+bankreg+(x86reg<<3)); OP((frm^1)<<2);
}

/**
 * Store an FR register (single-precision floating point) into an integer x86
 * register (eg for register-to-register moves)
 */
void static inline store_fr( int bankreg, int x86reg, int frn )
{
    OP(0x89);  OP(0x40+bankreg+(x86reg<<3)); OP((frn^1)<<2);
}


/**
 * Load a pointer to the back fp back into the specified x86 register. The
 * bankreg must have been previously loaded with FPSCR.
 * NB: 12 bytes
 */
static inline void load_xf_bank( int bankreg )
{
    NOT_r32( bankreg );
    SHR_imm8_r32( (21 - 6), bankreg ); // Extract bit 21 then *64 for bank size
    AND_imm8s_r32( 0x40, bankreg );    // Complete extraction
    OP(0x8D); OP(0x44+(bankreg<<3)); OP(0x28+bankreg); OP(REG_OFFSET(fr)); // LEA [ebp+bankreg+disp], bankreg
}

/**
 * Update the fr_bank pointer based on the current fpscr value.
 */
static inline void update_fr_bank( int fpscrreg )
{
    SHR_imm8_r32( (21 - 6), fpscrreg ); // Extract bit 21 then *64 for bank size
    AND_imm8s_r32( 0x40, fpscrreg );    // Complete extraction
    OP(0x8D); OP(0x44+(fpscrreg<<3)); OP(0x28+fpscrreg); OP(REG_OFFSET(fr)); // LEA [ebp+fpscrreg+disp], fpscrreg
    store_spreg( fpscrreg, REG_OFFSET(fr_bank) );
}
/**
 * Push FPUL (as a 32-bit float) onto the FPU stack
 */
static inline void push_fpul( )
{
    OP(0xD9); OP(0x45); OP(R_FPUL);
}

/**
 * Pop FPUL (as a 32-bit float) from the FPU stack
 */
static inline void pop_fpul( )
{
    OP(0xD9); OP(0x5D); OP(R_FPUL);
}

/**
 * Push a 32-bit float onto the FPU stack, with bankreg previously loaded
 * with the location of the current fp bank.
 */
static inline void push_fr( int bankreg, int frm ) 
{
    OP(0xD9); OP(0x40 + bankreg); OP((frm^1)<<2);  // FLD.S [bankreg + frm^1*4]
}

/**
 * Pop a 32-bit float from the FPU stack and store it back into the fp bank, 
 * with bankreg previously loaded with the location of the current fp bank.
 */
static inline void pop_fr( int bankreg, int frm )
{
    OP(0xD9); OP(0x58 + bankreg); OP((frm^1)<<2); // FST.S [bankreg + frm^1*4]
}

/**
 * Push a 64-bit double onto the FPU stack, with bankreg previously loaded
 * with the location of the current fp bank.
 */
static inline void push_dr( int bankreg, int frm )
{
    OP(0xDD); OP(0x40 + bankreg); OP(frm<<2); // FLD.D [bankreg + frm*4]
}

static inline void pop_dr( int bankreg, int frm )
{
    OP(0xDD); OP(0x58 + bankreg); OP(frm<<2); // FST.D [bankreg + frm*4]
}

/**
 * Note: clobbers EAX to make the indirect call - this isn't usually
 * a problem since the callee will usually clobber it anyway.
 */
static inline void call_func0( void *ptr )
{
    load_imm32(R_EAX, (uint32_t)ptr);
    CALL_r32(R_EAX);
}

static inline void call_func1( void *ptr, int arg1 )
{
    PUSH_r32(arg1);
    call_func0(ptr);
    ADD_imm8s_r32( 4, R_ESP );
}

static inline void call_func2( void *ptr, int arg1, int arg2 )
{
    PUSH_r32(arg2);
    PUSH_r32(arg1);
    call_func0(ptr);
    ADD_imm8s_r32( 8, R_ESP );
}

/**
 * Write a double (64-bit) value into memory, with the first word in arg2a, and
 * the second in arg2b
 * NB: 30 bytes
 */
static inline void MEM_WRITE_DOUBLE( int addr, int arg2a, int arg2b )
{
    ADD_imm8s_r32( 4, addr );
    PUSH_r32(arg2b);
    PUSH_r32(addr);
    ADD_imm8s_r32( -4, addr );
    PUSH_r32(arg2a);
    PUSH_r32(addr);
    call_func0(sh4_write_long);
    ADD_imm8s_r32( 8, R_ESP );
    call_func0(sh4_write_long);
    ADD_imm8s_r32( 8, R_ESP );
}

/**
 * Read a double (64-bit) value from memory, writing the first word into arg2a
 * and the second into arg2b. The addr must not be in EAX
 * NB: 27 bytes
 */
static inline void MEM_READ_DOUBLE( int addr, int arg2a, int arg2b )
{
    PUSH_r32(addr);
    call_func0(sh4_read_long);
    POP_r32(addr);
    PUSH_r32(R_EAX);
    ADD_imm8s_r32( 4, addr );
    PUSH_r32(addr);
    call_func0(sh4_read_long);
    ADD_imm8s_r32( 4, R_ESP );
    MOV_r32_r32( R_EAX, arg2b );
    POP_r32(arg2a);
}

/* Exception checks - Note that all exception checks will clobber EAX */
#define precheck() load_imm32(R_EDX, (pc-sh4_x86.block_start_pc-(sh4_x86.in_delay_slot?2:0))>>1)

#define check_priv( ) \
    if( !sh4_x86.priv_checked ) { \
	sh4_x86.priv_checked = TRUE;\
	precheck();\
	load_spreg( R_EAX, R_SR );\
	AND_imm32_r32( SR_MD, R_EAX );\
	if( sh4_x86.in_delay_slot ) {\
	    JE_exit( EXIT_SLOT_ILLEGAL );\
	} else {\
	    JE_exit( EXIT_ILLEGAL );\
	}\
    }\


static void check_priv_no_precheck()
{
    if( !sh4_x86.priv_checked ) {
	sh4_x86.priv_checked = TRUE;
	load_spreg( R_EAX, R_SR );
	AND_imm32_r32( SR_MD, R_EAX );
	if( sh4_x86.in_delay_slot ) {
	    JE_exit( EXIT_SLOT_ILLEGAL );
	} else {
	    JE_exit( EXIT_ILLEGAL );
	}
    }
}

#define check_fpuen( ) \
    if( !sh4_x86.fpuen_checked ) {\
	sh4_x86.fpuen_checked = TRUE;\
	precheck();\
	load_spreg( R_EAX, R_SR );\
	AND_imm32_r32( SR_FD, R_EAX );\
	if( sh4_x86.in_delay_slot ) {\
	    JNE_exit(EXIT_SLOT_FPU_DISABLED);\
	} else {\
	    JNE_exit(EXIT_FPU_DISABLED);\
	}\
    }

static void check_fpuen_no_precheck()
{
    if( !sh4_x86.fpuen_checked ) {
	sh4_x86.fpuen_checked = TRUE;
	load_spreg( R_EAX, R_SR );
	AND_imm32_r32( SR_FD, R_EAX );
	if( sh4_x86.in_delay_slot ) {
	    JNE_exit(EXIT_SLOT_FPU_DISABLED);
	} else {
	    JNE_exit(EXIT_FPU_DISABLED);
	}
    }

}

static void check_ralign16( int x86reg )
{
    TEST_imm32_r32( 0x00000001, x86reg );
    JNE_exit(EXIT_DATA_ADDR_READ);
}

static void check_walign16( int x86reg )
{
    TEST_imm32_r32( 0x00000001, x86reg );
    JNE_exit(EXIT_DATA_ADDR_WRITE);
}

static void check_ralign32( int x86reg )
{
    TEST_imm32_r32( 0x00000003, x86reg );
    JNE_exit(EXIT_DATA_ADDR_READ);
}
static void check_walign32( int x86reg )
{
    TEST_imm32_r32( 0x00000003, x86reg );
    JNE_exit(EXIT_DATA_ADDR_WRITE);
}

#define UNDEF()
#define MEM_RESULT(value_reg) if(value_reg != R_EAX) { MOV_r32_r32(R_EAX,value_reg); }
#define MEM_READ_BYTE( addr_reg, value_reg ) call_func1(sh4_read_byte, addr_reg ); MEM_RESULT(value_reg)
#define MEM_READ_WORD( addr_reg, value_reg ) call_func1(sh4_read_word, addr_reg ); MEM_RESULT(value_reg)
#define MEM_READ_LONG( addr_reg, value_reg ) call_func1(sh4_read_long, addr_reg ); MEM_RESULT(value_reg)
#define MEM_WRITE_BYTE( addr_reg, value_reg ) call_func2(sh4_write_byte, addr_reg, value_reg)
#define MEM_WRITE_WORD( addr_reg, value_reg ) call_func2(sh4_write_word, addr_reg, value_reg)
#define MEM_WRITE_LONG( addr_reg, value_reg ) call_func2(sh4_write_long, addr_reg, value_reg)

#define SLOTILLEGAL() precheck(); JMP_exit(EXIT_SLOT_ILLEGAL); sh4_x86.in_delay_slot = FALSE; return 1;



/**
 * Emit the 'start of block' assembly. Sets up the stack frame and save
 * SI/DI as required
 */
void sh4_translate_begin_block( sh4addr_t pc ) 
{
    PUSH_r32(R_EBP);
    /* mov &sh4r, ebp */
    load_imm32( R_EBP, (uint32_t)&sh4r );
    
    sh4_x86.in_delay_slot = FALSE;
    sh4_x86.priv_checked = FALSE;
    sh4_x86.fpuen_checked = FALSE;
    sh4_x86.branch_taken = FALSE;
    sh4_x86.backpatch_posn = 0;
    sh4_x86.block_start_pc = pc;
    sh4_x86.tstate = TSTATE_NONE;
}

/**
 * Exit the block to an absolute PC
 * Bytes: 29
 */
void exit_block( sh4addr_t pc, sh4addr_t endpc )
{
    load_imm32( R_ECX, pc );                            // 5
    store_spreg( R_ECX, REG_OFFSET(pc) );               // 3
    MOV_moff32_EAX( (uint32_t)xlat_get_lut_entry(pc) ); // 5
    AND_imm8s_r32( 0xFC, R_EAX ); // 3
    load_imm32( R_ECX, ((endpc - sh4_x86.block_start_pc)>>1)*sh4_cpu_period ); // 5
    ADD_r32_sh4r( R_ECX, REG_OFFSET(slice_cycle) );     // 6
    POP_r32(R_EBP);
    RET();
}

/**
 * Exit the block with sh4r.pc already written
 * Bytes: 15
 */
void exit_block_pcset( pc )
{
    load_imm32( R_ECX, ((pc - sh4_x86.block_start_pc)>>1)*sh4_cpu_period ); // 5
    ADD_r32_sh4r( R_ECX, REG_OFFSET(slice_cycle) );    // 6
    load_spreg( R_EAX, REG_OFFSET(pc) );
    call_func1(xlat_get_code,R_EAX);
    POP_r32(R_EBP);
    RET();
}

/**
 * Write the block trailer (exception handling block)
 */
void sh4_translate_end_block( sh4addr_t pc ) {
    if( sh4_x86.branch_taken == FALSE ) {
	// Didn't exit unconditionally already, so write the termination here
	exit_block( pc, pc );
    }
    if( sh4_x86.backpatch_posn != 0 ) {
	uint8_t *end_ptr = xlat_output;
	// Exception termination. Jump block for various exception codes:
	PUSH_imm32( EXC_DATA_ADDR_READ );
	JMP_rel8( 33, target1 );
	PUSH_imm32( EXC_DATA_ADDR_WRITE );
	JMP_rel8( 26, target2 );
	PUSH_imm32( EXC_ILLEGAL );
	JMP_rel8( 19, target3 );
	PUSH_imm32( EXC_SLOT_ILLEGAL ); 
	JMP_rel8( 12, target4 );
	PUSH_imm32( EXC_FPU_DISABLED ); 
	JMP_rel8( 5, target5 );
	PUSH_imm32( EXC_SLOT_FPU_DISABLED );
	// target
	JMP_TARGET(target1);
	JMP_TARGET(target2);
	JMP_TARGET(target3);
	JMP_TARGET(target4);
	JMP_TARGET(target5);
	// Raise exception
	load_spreg( R_ECX, REG_OFFSET(pc) );
	ADD_r32_r32( R_EDX, R_ECX );
	ADD_r32_r32( R_EDX, R_ECX );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	MOV_moff32_EAX( (uint32_t)&sh4_cpu_period );
	MUL_r32( R_EDX );
	ADD_r32_sh4r( R_EAX, REG_OFFSET(slice_cycle) );
	
	load_imm32( R_EAX, (uint32_t)sh4_raise_exception ); // 6
	CALL_r32( R_EAX ); // 2
	ADD_imm8s_r32( 4, R_ESP );
	load_spreg( R_EAX, REG_OFFSET(pc) );
	call_func1(xlat_get_code,R_EAX);
	POP_r32(R_EBP);
	RET();

	sh4_x86_do_backpatch( end_ptr );
    }

}


extern uint16_t *sh4_icache;
extern uint32_t sh4_icache_addr;

/**
 * Translate a single instruction. Delayed branches are handled specially
 * by translating both branch and delayed instruction as a single unit (as
 * 
 *
 * @return true if the instruction marks the end of a basic block
 * (eg a branch or 
 */
uint32_t sh4_x86_translate_instruction( sh4addr_t pc )
{
    uint32_t ir;
    /* Read instruction */
    uint32_t pageaddr = pc >> 12;
    if( sh4_icache != NULL && pageaddr == sh4_icache_addr ) {
	ir = sh4_icache[(pc&0xFFF)>>1];
    } else {
	sh4_icache = (uint16_t *)mem_get_page(pc);
	if( ((uint32_t)sh4_icache) < MAX_IO_REGIONS ) {
	    /* If someone's actually been so daft as to try to execute out of an IO
	     * region, fallback on the full-blown memory read
	     */
	    sh4_icache = NULL;
	    ir = sh4_read_word(pc);
	} else {
	    sh4_icache_addr = pageaddr;
	    ir = sh4_icache[(pc&0xFFF)>>1];
	}
    }

%%
/* ALU operations */
ADD Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
ADD #imm, Rn {:  
    load_reg( R_EAX, Rn );
    ADD_imm8s_r32( imm, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
ADDC Rm, Rn {:
    if( sh4_x86.tstate != TSTATE_C ) {
	LDC_t();
    }
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADC_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
ADDV Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETO_t();
    sh4_x86.tstate = TSTATE_O;
:}
AND Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    AND_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
AND #imm, R0 {:  
    load_reg( R_EAX, 0 );
    AND_imm32_r32(imm, R_EAX); 
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
AND.B #imm, @(R0, GBR) {: 
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_r32_r32( R_EAX, R_ECX );
    PUSH_r32(R_ECX);
    call_func0(sh4_read_byte);
    POP_r32(R_ECX);
    AND_imm32_r32(imm, R_EAX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
CMP/EQ Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
CMP/EQ #imm, R0 {:  
    load_reg( R_EAX, 0 );
    CMP_imm8s_r32(imm, R_EAX);
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
CMP/GE Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETGE_t();
    sh4_x86.tstate = TSTATE_GE;
:}
CMP/GT Rm, Rn {: 
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETG_t();
    sh4_x86.tstate = TSTATE_G;
:}
CMP/HI Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETA_t();
    sh4_x86.tstate = TSTATE_A;
:}
CMP/HS Rm, Rn {: 
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    CMP_r32_r32( R_EAX, R_ECX );
    SETAE_t();
    sh4_x86.tstate = TSTATE_AE;
 :}
CMP/PL Rn {: 
    load_reg( R_EAX, Rn );
    CMP_imm8s_r32( 0, R_EAX );
    SETG_t();
    sh4_x86.tstate = TSTATE_G;
:}
CMP/PZ Rn {:  
    load_reg( R_EAX, Rn );
    CMP_imm8s_r32( 0, R_EAX );
    SETGE_t();
    sh4_x86.tstate = TSTATE_GE;
:}
CMP/STR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    XOR_r32_r32( R_ECX, R_EAX );
    TEST_r8_r8( R_AL, R_AL );
    JE_rel8(13, target1);
    TEST_r8_r8( R_AH, R_AH ); // 2
    JE_rel8(9, target2);
    SHR_imm8_r32( 16, R_EAX ); // 3
    TEST_r8_r8( R_AL, R_AL ); // 2
    JE_rel8(2, target3);
    TEST_r8_r8( R_AH, R_AH ); // 2
    JMP_TARGET(target1);
    JMP_TARGET(target2);
    JMP_TARGET(target3);
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
DIV0S Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SHR_imm8_r32( 31, R_EAX );
    SHR_imm8_r32( 31, R_ECX );
    store_spreg( R_EAX, R_M );
    store_spreg( R_ECX, R_Q );
    CMP_r32_r32( R_EAX, R_ECX );
    SETNE_t();
    sh4_x86.tstate = TSTATE_NE;
:}
DIV0U {:  
    XOR_r32_r32( R_EAX, R_EAX );
    store_spreg( R_EAX, R_Q );
    store_spreg( R_EAX, R_M );
    store_spreg( R_EAX, R_T );
    sh4_x86.tstate = TSTATE_C; // works for DIV1
:}
DIV1 Rm, Rn {:
    load_spreg( R_ECX, R_M );
    load_reg( R_EAX, Rn );
    if( sh4_x86.tstate != TSTATE_C ) {
	LDC_t();
    }
    RCL1_r32( R_EAX );
    SETC_r8( R_DL ); // Q'
    CMP_sh4r_r32( R_Q, R_ECX );
    JE_rel8(5, mqequal);
    ADD_sh4r_r32( REG_OFFSET(r[Rm]), R_EAX );
    JMP_rel8(3, end);
    JMP_TARGET(mqequal);
    SUB_sh4r_r32( REG_OFFSET(r[Rm]), R_EAX );
    JMP_TARGET(end);
    store_reg( R_EAX, Rn ); // Done with Rn now
    SETC_r8(R_AL); // tmp1
    XOR_r8_r8( R_DL, R_AL ); // Q' = Q ^ tmp1
    XOR_r8_r8( R_AL, R_CL ); // Q'' = Q' ^ M
    store_spreg( R_ECX, R_Q );
    XOR_imm8s_r32( 1, R_AL );   // T = !Q'
    MOVZX_r8_r32( R_AL, R_EAX );
    store_spreg( R_EAX, R_T );
    sh4_x86.tstate = TSTATE_NONE;
:}
DMULS.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    IMUL_r32(R_ECX);
    store_spreg( R_EDX, R_MACH );
    store_spreg( R_EAX, R_MACL );
    sh4_x86.tstate = TSTATE_NONE;
:}
DMULU.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MUL_r32(R_ECX);
    store_spreg( R_EDX, R_MACH );
    store_spreg( R_EAX, R_MACL );    
    sh4_x86.tstate = TSTATE_NONE;
:}
DT Rn {:  
    load_reg( R_EAX, Rn );
    ADD_imm8s_r32( -1, R_EAX );
    store_reg( R_EAX, Rn );
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
EXTS.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVSX_r8_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTS.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVSX_r16_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTU.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVZX_r8_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
EXTU.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOVZX_r16_r32( R_EAX, R_EAX );
    store_reg( R_EAX, Rn );
:}
MAC.L @Rm+, @Rn+ {:  
    load_reg( R_ECX, Rm );
    precheck();
    check_ralign32( R_ECX );
    load_reg( R_ECX, Rn );
    check_ralign32( R_ECX );
    ADD_imm8s_sh4r( 4, REG_OFFSET(r[Rn]) );
    MEM_READ_LONG( R_ECX, R_EAX );
    PUSH_r32( R_EAX );
    load_reg( R_ECX, Rm );
    ADD_imm8s_sh4r( 4, REG_OFFSET(r[Rm]) );
    MEM_READ_LONG( R_ECX, R_EAX );
    POP_r32( R_ECX );
    IMUL_r32( R_ECX );
    ADD_r32_sh4r( R_EAX, R_MACL );
    ADC_r32_sh4r( R_EDX, R_MACH );

    load_spreg( R_ECX, R_S );
    TEST_r32_r32(R_ECX, R_ECX);
    JE_rel8( 7, nosat );
    call_func0( signsat48 );
    JMP_TARGET( nosat );
    sh4_x86.tstate = TSTATE_NONE;
:}
MAC.W @Rm+, @Rn+ {:  
    load_reg( R_ECX, Rm );
    precheck();
    check_ralign16( R_ECX );
    load_reg( R_ECX, Rn );
    check_ralign16( R_ECX );
    ADD_imm8s_sh4r( 2, REG_OFFSET(r[Rn]) );
    MEM_READ_WORD( R_ECX, R_EAX );
    PUSH_r32( R_EAX );
    load_reg( R_ECX, Rm );
    ADD_imm8s_sh4r( 2, REG_OFFSET(r[Rm]) );
    MEM_READ_WORD( R_ECX, R_EAX );
    POP_r32( R_ECX );
    IMUL_r32( R_ECX );

    load_spreg( R_ECX, R_S );
    TEST_r32_r32( R_ECX, R_ECX );
    JE_rel8( 47, nosat );

    ADD_r32_sh4r( R_EAX, R_MACL );  // 6
    JNO_rel8( 51, end );            // 2
    load_imm32( R_EDX, 1 );         // 5
    store_spreg( R_EDX, R_MACH );   // 6
    JS_rel8( 13, positive );        // 2
    load_imm32( R_EAX, 0x80000000 );// 5
    store_spreg( R_EAX, R_MACL );   // 6
    JMP_rel8( 25, end2 );           // 2

    JMP_TARGET(positive);
    load_imm32( R_EAX, 0x7FFFFFFF );// 5
    store_spreg( R_EAX, R_MACL );   // 6
    JMP_rel8( 12, end3);            // 2

    JMP_TARGET(nosat);
    ADD_r32_sh4r( R_EAX, R_MACL );  // 6
    ADC_r32_sh4r( R_EDX, R_MACH );  // 6
    JMP_TARGET(end);
    JMP_TARGET(end2);
    JMP_TARGET(end3);
    sh4_x86.tstate = TSTATE_NONE;
:}
MOVT Rn {:  
    load_spreg( R_EAX, R_T );
    store_reg( R_EAX, Rn );
:}
MUL.L Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MUL_r32( R_ECX );
    store_spreg( R_EAX, R_MACL );
    sh4_x86.tstate = TSTATE_NONE;
:}
MULS.W Rm, Rn {:
    load_reg16s( R_EAX, Rm );
    load_reg16s( R_ECX, Rn );
    MUL_r32( R_ECX );
    store_spreg( R_EAX, R_MACL );
    sh4_x86.tstate = TSTATE_NONE;
:}
MULU.W Rm, Rn {:  
    load_reg16u( R_EAX, Rm );
    load_reg16u( R_ECX, Rn );
    MUL_r32( R_ECX );
    store_spreg( R_EAX, R_MACL );
    sh4_x86.tstate = TSTATE_NONE;
:}
NEG Rm, Rn {:
    load_reg( R_EAX, Rm );
    NEG_r32( R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
NEGC Rm, Rn {:  
    load_reg( R_EAX, Rm );
    XOR_r32_r32( R_ECX, R_ECX );
    LDC_t();
    SBB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
NOT Rm, Rn {:  
    load_reg( R_EAX, Rm );
    NOT_r32( R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
OR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
OR #imm, R0 {:
    load_reg( R_EAX, 0 );
    OR_imm32_r32(imm, R_EAX);
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
OR.B #imm, @(R0, GBR) {:  
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_r32_r32( R_EAX, R_ECX );
    PUSH_r32(R_ECX);
    call_func0(sh4_read_byte);
    POP_r32(R_ECX);
    OR_imm32_r32(imm, R_EAX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
ROTCL Rn {:
    load_reg( R_EAX, Rn );
    if( sh4_x86.tstate != TSTATE_C ) {
	LDC_t();
    }
    RCL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
ROTCR Rn {:  
    load_reg( R_EAX, Rn );
    if( sh4_x86.tstate != TSTATE_C ) {
	LDC_t();
    }
    RCR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
ROTL Rn {:  
    load_reg( R_EAX, Rn );
    ROL1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
ROTR Rn {:  
    load_reg( R_EAX, Rn );
    ROR1_r32( R_EAX );
    store_reg( R_EAX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
SHAD Rm, Rn {:
    /* Annoyingly enough, not directly convertible */
    load_reg( R_EAX, Rn );
    load_reg( R_ECX, Rm );
    CMP_imm32_r32( 0, R_ECX );
    JGE_rel8(16, doshl);
                    
    NEG_r32( R_ECX );      // 2
    AND_imm8_r8( 0x1F, R_CL ); // 3
    JE_rel8( 4, emptysar);     // 2
    SAR_r32_CL( R_EAX );       // 2
    JMP_rel8(10, end);          // 2

    JMP_TARGET(emptysar);
    SAR_imm8_r32(31, R_EAX );  // 3
    JMP_rel8(5, end2);

    JMP_TARGET(doshl);
    AND_imm8_r8( 0x1F, R_CL ); // 3
    SHL_r32_CL( R_EAX );       // 2
    JMP_TARGET(end);
    JMP_TARGET(end2);
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLD Rm, Rn {:  
    load_reg( R_EAX, Rn );
    load_reg( R_ECX, Rm );
    CMP_imm32_r32( 0, R_ECX );
    JGE_rel8(15, doshl);

    NEG_r32( R_ECX );      // 2
    AND_imm8_r8( 0x1F, R_CL ); // 3
    JE_rel8( 4, emptyshr );
    SHR_r32_CL( R_EAX );       // 2
    JMP_rel8(9, end);          // 2

    JMP_TARGET(emptyshr);
    XOR_r32_r32( R_EAX, R_EAX );
    JMP_rel8(5, end2);

    JMP_TARGET(doshl);
    AND_imm8_r8( 0x1F, R_CL ); // 3
    SHL_r32_CL( R_EAX );       // 2
    JMP_TARGET(end);
    JMP_TARGET(end2);
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHAL Rn {: 
    load_reg( R_EAX, Rn );
    SHL1_r32( R_EAX );
    SETC_t();
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_C;
:}
SHAR Rn {:  
    load_reg( R_EAX, Rn );
    SAR1_r32( R_EAX );
    SETC_t();
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_C;
:}
SHLL Rn {:  
    load_reg( R_EAX, Rn );
    SHL1_r32( R_EAX );
    SETC_t();
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_C;
:}
SHLL2 Rn {:
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 2, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLL8 Rn {:  
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 8, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLL16 Rn {:  
    load_reg( R_EAX, Rn );
    SHL_imm8_r32( 16, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLR Rn {:  
    load_reg( R_EAX, Rn );
    SHR1_r32( R_EAX );
    SETC_t();
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_C;
:}
SHLR2 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 2, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLR8 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 8, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SHLR16 Rn {:  
    load_reg( R_EAX, Rn );
    SHR_imm8_r32( 16, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SUB Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SUB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
SUBC Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    if( sh4_x86.tstate != TSTATE_C ) {
	LDC_t();
    }
    SBB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
SUBV Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SUB_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    SETO_t();
    sh4_x86.tstate = TSTATE_O;
:}
SWAP.B Rm, Rn {:  
    load_reg( R_EAX, Rm );
    XCHG_r8_r8( R_AL, R_AH );
    store_reg( R_EAX, Rn );
:}
SWAP.W Rm, Rn {:  
    load_reg( R_EAX, Rm );
    MOV_r32_r32( R_EAX, R_ECX );
    SHL_imm8_r32( 16, R_ECX );
    SHR_imm8_r32( 16, R_EAX );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
TAS.B @Rn {:  
    load_reg( R_ECX, Rn );
    MEM_READ_BYTE( R_ECX, R_EAX );
    TEST_r8_r8( R_AL, R_AL );
    SETE_t();
    OR_imm8_r8( 0x80, R_AL );
    load_reg( R_ECX, Rn );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
TST Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    TEST_r32_r32( R_EAX, R_ECX );
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
TST #imm, R0 {:  
    load_reg( R_EAX, 0 );
    TEST_imm32_r32( imm, R_EAX );
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
TST.B #imm, @(R0, GBR) {:  
    load_reg( R_EAX, 0);
    load_reg( R_ECX, R_GBR);
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    TEST_imm8_r8( imm, R_AL );
    SETE_t();
    sh4_x86.tstate = TSTATE_E;
:}
XOR Rm, Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    XOR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
XOR #imm, R0 {:  
    load_reg( R_EAX, 0 );
    XOR_imm32_r32( imm, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
XOR.B #imm, @(R0, GBR) {:  
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_r32_r32( R_EAX, R_ECX );
    PUSH_r32(R_ECX);
    call_func0(sh4_read_byte);
    POP_r32(R_ECX);
    XOR_imm32_r32( imm, R_EAX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
XTRCT Rm, Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    SHL_imm8_r32( 16, R_EAX );
    SHR_imm8_r32( 16, R_ECX );
    OR_r32_r32( R_EAX, R_ECX );
    store_reg( R_ECX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}

/* Data move instructions */
MOV Rm, Rn {:  
    load_reg( R_EAX, Rm );
    store_reg( R_EAX, Rn );
:}
MOV #imm, Rn {:  
    load_imm32( R_EAX, imm );
    store_reg( R_EAX, Rn );
:}
MOV.B Rm, @Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B Rm, @-Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    ADD_imm8s_r32( -1, R_ECX );
    store_reg( R_ECX, Rn );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B R0, @(disp, GBR) {:  
    load_reg( R_EAX, 0 );
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B R0, @(disp, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_imm32_r32( disp, R_ECX );
    MEM_WRITE_BYTE( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B @Rm+, Rn {:  
    load_reg( R_ECX, Rm );
    MOV_r32_r32( R_ECX, R_EAX );
    ADD_imm8s_r32( 1, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B @(disp, GBR), R0 {:  
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.B @(disp, Rm), R0 {:  
    load_reg( R_ECX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    MEM_READ_BYTE( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L Rm, @Rn {:
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32(R_ECX);
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L Rm, @-Rn {:  
    load_reg( R_EAX, Rm );
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    precheck();
    check_walign32( R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L R0, @(disp, GBR) {:  
    load_spreg( R_ECX, R_GBR );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_walign32( R_ECX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L Rm, @(disp, Rn) {:  
    load_reg( R_ECX, Rn );
    load_reg( R_EAX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_walign32( R_ECX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    precheck();
    check_ralign32( R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L @Rm+, Rn {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    precheck();
    check_ralign32( R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L @(disp, GBR), R0 {:
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_ralign32( R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.L @(disp, PC), Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	uint32_t target = (pc & 0xFFFFFFFC) + disp + 4;
	char *ptr = mem_get_region(target);
	if( ptr != NULL ) {
	    MOV_moff32_EAX( (uint32_t)ptr );
	} else {
	    load_imm32( R_ECX, target );
	    MEM_READ_LONG( R_ECX, R_EAX );
	}
	store_reg( R_EAX, Rn );
	sh4_x86.tstate = TSTATE_NONE;
    }
:}
MOV.L @(disp, Rm), Rn {:  
    load_reg( R_ECX, Rm );
    ADD_imm8s_r32( disp, R_ECX );
    precheck();
    check_ralign32( R_ECX );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W Rm, @Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign16( R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_WORD( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W Rm, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign16( R_ECX );
    load_reg( R_EAX, Rm );
    ADD_imm8s_r32( -2, R_ECX );
    store_reg( R_ECX, Rn );
    MEM_WRITE_WORD( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W Rm, @(R0, Rn) {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    ADD_r32_r32( R_EAX, R_ECX );
    precheck();
    check_walign16( R_ECX );
    load_reg( R_EAX, Rm );
    MEM_WRITE_WORD( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W R0, @(disp, GBR) {:  
    load_spreg( R_ECX, R_GBR );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_walign16( R_ECX );
    MEM_WRITE_WORD( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W R0, @(disp, Rn) {:  
    load_reg( R_ECX, Rn );
    load_reg( R_EAX, 0 );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_walign16( R_ECX );
    MEM_WRITE_WORD( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W @Rm, Rn {:  
    load_reg( R_ECX, Rm );
    precheck();
    check_ralign16( R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W @Rm+, Rn {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign16( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 2, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W @(R0, Rm), Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rm );
    ADD_r32_r32( R_EAX, R_ECX );
    precheck();
    check_ralign16( R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W @(disp, GBR), R0 {:  
    load_spreg( R_ECX, R_GBR );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_ralign16( R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOV.W @(disp, PC), Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_imm32( R_ECX, pc + disp + 4 );
	MEM_READ_WORD( R_ECX, R_EAX );
	store_reg( R_EAX, Rn );
	sh4_x86.tstate = TSTATE_NONE;
    }
:}
MOV.W @(disp, Rm), R0 {:  
    load_reg( R_ECX, Rm );
    ADD_imm32_r32( disp, R_ECX );
    precheck();
    check_ralign16( R_ECX );
    MEM_READ_WORD( R_ECX, R_EAX );
    store_reg( R_EAX, 0 );
    sh4_x86.tstate = TSTATE_NONE;
:}
MOVA @(disp, PC), R0 {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_imm32( R_ECX, (pc & 0xFFFFFFFC) + disp + 4 );
	store_reg( R_ECX, 0 );
    }
:}
MOVCA.L R0, @Rn {:  
    load_reg( R_EAX, 0 );
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}

/* Control transfer instructions */
BF disp {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	JT_rel8( 29, nottaken );
	exit_block( disp + pc + 4, pc+2 );
	JMP_TARGET(nottaken);
	return 2;
    }
:}
BF/S disp {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	sh4_x86.in_delay_slot = TRUE;
	if( sh4_x86.tstate == TSTATE_NONE ) {
	    CMP_imm8s_sh4r( 1, R_T );
	    sh4_x86.tstate = TSTATE_E;
	}
	OP(0x0F); OP(0x80+sh4_x86.tstate); uint32_t *patch = (uint32_t *)xlat_output; OP32(0); // JNE rel32
	sh4_x86_translate_instruction(pc+2);
	exit_block( disp + pc + 4, pc+4 );
	// not taken
	*patch = (xlat_output - ((uint8_t *)patch)) - 4;
	sh4_x86_translate_instruction(pc+2);
	return 4;
    }
:}
BRA disp {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86_translate_instruction( pc + 2 );
	exit_block( disp + pc + 4, pc+4 );
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
BRAF Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_reg( R_EAX, Rn );
	ADD_imm32_r32( pc + 4, R_EAX );
	store_spreg( R_EAX, REG_OFFSET(pc) );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86.tstate = TSTATE_NONE;
	sh4_x86_translate_instruction( pc + 2 );
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
BSR disp {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_imm32( R_EAX, pc + 4 );
	store_spreg( R_EAX, R_PR );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86_translate_instruction( pc + 2 );
	exit_block( disp + pc + 4, pc+4 );
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
BSRF Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_imm32( R_ECX, pc + 4 );
	store_spreg( R_ECX, R_PR );
	ADD_sh4r_r32( REG_OFFSET(r[Rn]), R_ECX );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86.tstate = TSTATE_NONE;
	sh4_x86_translate_instruction( pc + 2 );
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
BT disp {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	JF_rel8( 29, nottaken );
	exit_block( disp + pc + 4, pc+2 );
	JMP_TARGET(nottaken);
	return 2;
    }
:}
BT/S disp {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	sh4_x86.in_delay_slot = TRUE;
	if( sh4_x86.tstate == TSTATE_NONE ) {
	    CMP_imm8s_sh4r( 1, R_T );
	    sh4_x86.tstate = TSTATE_E;
	}
	OP(0x0F); OP(0x80+(sh4_x86.tstate^1)); uint32_t *patch = (uint32_t *)xlat_output; OP32(0); // JE rel32
	sh4_x86_translate_instruction(pc+2);
	exit_block( disp + pc + 4, pc+4 );
	// not taken
	*patch = (xlat_output - ((uint8_t *)patch)) - 4;
	sh4_x86_translate_instruction(pc+2);
	return 4;
    }
:}
JMP @Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_reg( R_ECX, Rn );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86_translate_instruction(pc+2);
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
JSR @Rn {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_imm32( R_EAX, pc + 4 );
	store_spreg( R_EAX, R_PR );
	load_reg( R_ECX, Rn );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86_translate_instruction(pc+2);
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
RTE {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	check_priv();
	load_spreg( R_ECX, R_SPC );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	load_spreg( R_EAX, R_SSR );
	call_func1( sh4_write_sr, R_EAX );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86.priv_checked = FALSE;
	sh4_x86.fpuen_checked = FALSE;
	sh4_x86.tstate = TSTATE_NONE;
	sh4_x86_translate_instruction(pc+2);
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
RTS {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	load_spreg( R_ECX, R_PR );
	store_spreg( R_ECX, REG_OFFSET(pc) );
	sh4_x86.in_delay_slot = TRUE;
	sh4_x86_translate_instruction(pc+2);
	exit_block_pcset(pc+2);
	sh4_x86.branch_taken = TRUE;
	return 4;
    }
:}
TRAPA #imm {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	PUSH_imm32( imm );
	call_func0( sh4_raise_trap );
	ADD_imm8s_r32( 4, R_ESP );
	sh4_x86.tstate = TSTATE_NONE;
	exit_block_pcset(pc);
	sh4_x86.branch_taken = TRUE;
	return 2;
    }
:}
UNDEF {:  
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	precheck();
	JMP_exit(EXIT_ILLEGAL);
	return 2;
    }
:}

CLRMAC {:  
    XOR_r32_r32(R_EAX, R_EAX);
    store_spreg( R_EAX, R_MACL );
    store_spreg( R_EAX, R_MACH );
    sh4_x86.tstate = TSTATE_NONE;
:}
CLRS {:
    CLC();
    SETC_sh4r(R_S);
    sh4_x86.tstate = TSTATE_C;
:}
CLRT {:  
    CLC();
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}
SETS {:  
    STC();
    SETC_sh4r(R_S);
    sh4_x86.tstate = TSTATE_C;
:}
SETT {:  
    STC();
    SETC_t();
    sh4_x86.tstate = TSTATE_C;
:}

/* Floating point moves */
FMOV FRm, FRn {:  
    /* As horrible as this looks, it's actually covering 5 separate cases:
     * 1. 32-bit fr-to-fr (PR=0)
     * 2. 64-bit dr-to-dr (PR=1, FRm&1 == 0, FRn&1 == 0 )
     * 3. 64-bit dr-to-xd (PR=1, FRm&1 == 0, FRn&1 == 1 )
     * 4. 64-bit xd-to-dr (PR=1, FRm&1 == 1, FRn&1 == 0 )
     * 5. 64-bit xd-to-xd (PR=1, FRm&1 == 1, FRn&1 == 1 )
     */
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    load_fr_bank( R_EDX );
    TEST_imm32_r32( FPSCR_SZ, R_ECX );
    JNE_rel8(8, doublesize);
    load_fr( R_EDX, R_EAX, FRm ); // PR=0 branch
    store_fr( R_EDX, R_EAX, FRn );
    if( FRm&1 ) {
	JMP_rel8(24, end);
	JMP_TARGET(doublesize);
	load_xf_bank( R_ECX ); 
	load_fr( R_ECX, R_EAX, FRm-1 );
	if( FRn&1 ) {
	    load_fr( R_ECX, R_EDX, FRm );
	    store_fr( R_ECX, R_EAX, FRn-1 );
	    store_fr( R_ECX, R_EDX, FRn );
	} else /* FRn&1 == 0 */ {
	    load_fr( R_ECX, R_ECX, FRm );
	    store_fr( R_EDX, R_EAX, FRn );
	    store_fr( R_EDX, R_ECX, FRn+1 );
	}
	JMP_TARGET(end);
    } else /* FRm&1 == 0 */ {
	if( FRn&1 ) {
	    JMP_rel8(24, end);
	    load_xf_bank( R_ECX );
	    load_fr( R_EDX, R_EAX, FRm );
	    load_fr( R_EDX, R_EDX, FRm+1 );
	    store_fr( R_ECX, R_EAX, FRn-1 );
	    store_fr( R_ECX, R_EDX, FRn );
	    JMP_TARGET(end);
	} else /* FRn&1 == 0 */ {
	    JMP_rel8(12, end);
	    load_fr( R_EDX, R_EAX, FRm );
	    load_fr( R_EDX, R_ECX, FRm+1 );
	    store_fr( R_EDX, R_EAX, FRn );
	    store_fr( R_EDX, R_ECX, FRn+1 );
	    JMP_TARGET(end);
	}
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV FRm, @Rn {: 
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(20, doublesize);
    load_fr_bank( R_EDX );
    load_fr( R_EDX, R_EAX, FRm );
    MEM_WRITE_LONG( R_ECX, R_EAX ); // 12
    if( FRm&1 ) {
	JMP_rel8( 48, end );
	JMP_TARGET(doublesize);
	load_xf_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    } else {
	JMP_rel8( 39, end );
	JMP_TARGET(doublesize);
	load_fr_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV @Rm, FRn {:  
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rm );
    check_ralign32( R_ECX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(19, doublesize);
    MEM_READ_LONG( R_ECX, R_EAX );
    load_fr_bank( R_EDX );
    store_fr( R_EDX, R_EAX, FRn );
    if( FRn&1 ) {
	JMP_rel8(48, end);
	JMP_TARGET(doublesize);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_spreg( R_EDX, R_FPSCR ); // assume read_long clobbered it
	load_xf_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    } else {
	JMP_rel8(36, end);
	JMP_TARGET(doublesize);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_fr_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV FRm, @-Rn {:  
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(26, doublesize);
    load_fr_bank( R_EDX );
    load_fr( R_EDX, R_EAX, FRm );
    ADD_imm8s_r32(-4,R_ECX);
    store_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX ); // 12
    if( FRm&1 ) {
	JMP_rel8( 54, end );
	JMP_TARGET(doublesize);
	load_xf_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	ADD_imm8s_r32(-8,R_ECX);
	store_reg( R_ECX, Rn );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    } else {
	JMP_rel8( 45, end );
	JMP_TARGET(doublesize);
	load_fr_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	ADD_imm8s_r32(-8,R_ECX);
	store_reg( R_ECX, Rn );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV @Rm+, FRn {:
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rm );
    check_ralign32( R_ECX );
    MOV_r32_r32( R_ECX, R_EAX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(25, doublesize);
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    load_fr_bank( R_EDX );
    store_fr( R_EDX, R_EAX, FRn );
    if( FRn&1 ) {
	JMP_rel8(54, end);
	JMP_TARGET(doublesize);
	ADD_imm8s_r32( 8, R_EAX );
	store_reg(R_EAX, Rm);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_spreg( R_EDX, R_FPSCR ); // assume read_long clobbered it
	load_xf_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    } else {
	JMP_rel8(42, end);
	ADD_imm8s_r32( 8, R_EAX );
	store_reg(R_EAX, Rm);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_fr_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV FRm, @(R0, Rn) {:  
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rn );
    ADD_sh4r_r32( REG_OFFSET(r[0]), R_ECX );
    check_walign32( R_ECX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(20, doublesize);
    load_fr_bank( R_EDX );
    load_fr( R_EDX, R_EAX, FRm );
    MEM_WRITE_LONG( R_ECX, R_EAX ); // 12
    if( FRm&1 ) {
	JMP_rel8( 48, end );
	JMP_TARGET(doublesize);
	load_xf_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    } else {
	JMP_rel8( 39, end );
	JMP_TARGET(doublesize);
	load_fr_bank( R_EDX );
	load_fr( R_EDX, R_EAX, FRm&0x0E );
	load_fr( R_EDX, R_EDX, FRm|0x01 );
	MEM_WRITE_DOUBLE( R_ECX, R_EAX, R_EDX );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FMOV @(R0, Rm), FRn {:  
    precheck();
    check_fpuen_no_precheck();
    load_reg( R_ECX, Rm );
    ADD_sh4r_r32( REG_OFFSET(r[0]), R_ECX );
    check_ralign32( R_ECX );
    load_spreg( R_EDX, R_FPSCR );
    TEST_imm32_r32( FPSCR_SZ, R_EDX );
    JNE_rel8(19, doublesize);
    MEM_READ_LONG( R_ECX, R_EAX );
    load_fr_bank( R_EDX );
    store_fr( R_EDX, R_EAX, FRn );
    if( FRn&1 ) {
	JMP_rel8(48, end);
	JMP_TARGET(doublesize);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_spreg( R_EDX, R_FPSCR ); // assume read_long clobbered it
	load_xf_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    } else {
	JMP_rel8(36, end);
	JMP_TARGET(doublesize);
	MEM_READ_DOUBLE( R_ECX, R_EAX, R_ECX );
	load_fr_bank( R_EDX );
	store_fr( R_EDX, R_EAX, FRn&0x0E );
	store_fr( R_EDX, R_ECX, FRn|0x01 );
	JMP_TARGET(end);
    }
    sh4_x86.tstate = TSTATE_NONE;
:}
FLDI0 FRn {:  /* IFF PR=0 */
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(8, end);
    XOR_r32_r32( R_EAX, R_EAX );
    load_spreg( R_ECX, REG_OFFSET(fr_bank) );
    store_fr( R_ECX, R_EAX, FRn );
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FLDI1 FRn {:  /* IFF PR=0 */
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(11, end);
    load_imm32(R_EAX, 0x3F800000);
    load_spreg( R_ECX, REG_OFFSET(fr_bank) );
    store_fr( R_ECX, R_EAX, FRn );
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}

FLOAT FPUL, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    load_spreg(R_EDX, REG_OFFSET(fr_bank));
    FILD_sh4r(R_FPUL);
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(5, doubleprec);
    pop_fr( R_EDX, FRn );
    JMP_rel8(3, end);
    JMP_TARGET(doubleprec);
    pop_dr( R_EDX, FRn );
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FTRC FRm, FPUL {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    load_fr_bank( R_EDX );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(5, doubleprec);
    push_fr( R_EDX, FRm );
    JMP_rel8(3, doop);
    JMP_TARGET(doubleprec);
    push_dr( R_EDX, FRm );
    JMP_TARGET( doop );
    load_imm32( R_ECX, (uint32_t)&max_int );
    FILD_r32ind( R_ECX );
    FCOMIP_st(1);
    JNA_rel8( 32, sat );
    load_imm32( R_ECX, (uint32_t)&min_int );  // 5
    FILD_r32ind( R_ECX );           // 2
    FCOMIP_st(1);                   // 2
    JAE_rel8( 21, sat2 );            // 2
    load_imm32( R_EAX, (uint32_t)&save_fcw );
    FNSTCW_r32ind( R_EAX );
    load_imm32( R_EDX, (uint32_t)&trunc_fcw );
    FLDCW_r32ind( R_EDX );
    FISTP_sh4r(R_FPUL);             // 3
    FLDCW_r32ind( R_EAX );
    JMP_rel8( 9, end );             // 2

    JMP_TARGET(sat);
    JMP_TARGET(sat2);
    MOV_r32ind_r32( R_ECX, R_ECX ); // 2
    store_spreg( R_ECX, R_FPUL );
    FPOP_st();
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FLDS FRm, FPUL {:  
    check_fpuen();
    load_fr_bank( R_ECX );
    load_fr( R_ECX, R_EAX, FRm );
    store_spreg( R_EAX, R_FPUL );
    sh4_x86.tstate = TSTATE_NONE;
:}
FSTS FPUL, FRn {:  
    check_fpuen();
    load_fr_bank( R_ECX );
    load_spreg( R_EAX, R_FPUL );
    store_fr( R_ECX, R_EAX, FRn );
    sh4_x86.tstate = TSTATE_NONE;
:}
FCNVDS FRm, FPUL {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JE_rel8(9, end); // only when PR=1
    load_fr_bank( R_ECX );
    push_dr( R_ECX, FRm );
    pop_fpul();
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FCNVSD FPUL, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JE_rel8(9, end); // only when PR=1
    load_fr_bank( R_ECX );
    push_fpul();
    pop_dr( R_ECX, FRn );
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}

/* Floating point instructions */
FABS FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    load_fr_bank( R_EDX );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(10, doubleprec);
    push_fr(R_EDX, FRn); // 3
    FABS_st0(); // 2
    pop_fr( R_EDX, FRn); //3
    JMP_rel8(8,end); // 2
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRn);
    FABS_st0();
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FADD FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(13,doubleprec);
    push_fr(R_EDX, FRm);
    push_fr(R_EDX, FRn);
    FADDP_st(1);
    pop_fr(R_EDX, FRn);
    JMP_rel8(11,end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRm);
    push_dr(R_EDX, FRn);
    FADDP_st(1);
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FDIV FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(13, doubleprec);
    push_fr(R_EDX, FRn);
    push_fr(R_EDX, FRm);
    FDIVP_st(1);
    pop_fr(R_EDX, FRn);
    JMP_rel8(11, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRn);
    push_dr(R_EDX, FRm);
    FDIVP_st(1);
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FMAC FR0, FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    load_spreg( R_EDX, REG_OFFSET(fr_bank));
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(18, doubleprec);
    push_fr( R_EDX, 0 );
    push_fr( R_EDX, FRm );
    FMULP_st(1);
    push_fr( R_EDX, FRn );
    FADDP_st(1);
    pop_fr( R_EDX, FRn );
    JMP_rel8(16, end);
    JMP_TARGET(doubleprec);
    push_dr( R_EDX, 0 );
    push_dr( R_EDX, FRm );
    FMULP_st(1);
    push_dr( R_EDX, FRn );
    FADDP_st(1);
    pop_dr( R_EDX, FRn );
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}

FMUL FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(13, doubleprec);
    push_fr(R_EDX, FRm);
    push_fr(R_EDX, FRn);
    FMULP_st(1);
    pop_fr(R_EDX, FRn);
    JMP_rel8(11, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRm);
    push_dr(R_EDX, FRn);
    FMULP_st(1);
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FNEG FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(10, doubleprec);
    push_fr(R_EDX, FRn);
    FCHS_st0();
    pop_fr(R_EDX, FRn);
    JMP_rel8(8, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRn);
    FCHS_st0();
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FSRRA FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(12, end); // PR=0 only
    FLD1_st0();
    push_fr(R_EDX, FRn);
    FSQRT_st0();
    FDIVP_st(1);
    pop_fr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FSQRT FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(10, doubleprec);
    push_fr(R_EDX, FRn);
    FSQRT_st0();
    pop_fr(R_EDX, FRn);
    JMP_rel8(8, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRn);
    FSQRT_st0();
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}
FSUB FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(13, doubleprec);
    push_fr(R_EDX, FRn);
    push_fr(R_EDX, FRm);
    FSUBP_st(1);
    pop_fr(R_EDX, FRn);
    JMP_rel8(11, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRn);
    push_dr(R_EDX, FRm);
    FSUBP_st(1);
    pop_dr(R_EDX, FRn);
    JMP_TARGET(end);
    sh4_x86.tstate = TSTATE_NONE;
:}

FCMP/EQ FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(8, doubleprec);
    push_fr(R_EDX, FRm);
    push_fr(R_EDX, FRn);
    JMP_rel8(6, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRm);
    push_dr(R_EDX, FRn);
    JMP_TARGET(end);
    FCOMIP_st(1);
    SETE_t();
    FPOP_st();
    sh4_x86.tstate = TSTATE_NONE;
:}
FCMP/GT FRm, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    load_fr_bank( R_EDX );
    JNE_rel8(8, doubleprec);
    push_fr(R_EDX, FRm);
    push_fr(R_EDX, FRn);
    JMP_rel8(6, end);
    JMP_TARGET(doubleprec);
    push_dr(R_EDX, FRm);
    push_dr(R_EDX, FRn);
    JMP_TARGET(end);
    FCOMIP_st(1);
    SETA_t();
    FPOP_st();
    sh4_x86.tstate = TSTATE_NONE;
:}

FSCA FPUL, FRn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8( 21, doubleprec );
    load_fr_bank( R_ECX );
    ADD_imm8s_r32( (FRn&0x0E)<<2, R_ECX );
    load_spreg( R_EDX, R_FPUL );
    call_func2( sh4_fsca, R_EDX, R_ECX );
    JMP_TARGET(doubleprec);
    sh4_x86.tstate = TSTATE_NONE;
:}
FIPR FVm, FVn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8(44, doubleprec);
    
    load_fr_bank( R_ECX );
    push_fr( R_ECX, FVm<<2 );
    push_fr( R_ECX, FVn<<2 );
    FMULP_st(1);
    push_fr( R_ECX, (FVm<<2)+1);
    push_fr( R_ECX, (FVn<<2)+1);
    FMULP_st(1);
    FADDP_st(1);
    push_fr( R_ECX, (FVm<<2)+2);
    push_fr( R_ECX, (FVn<<2)+2);
    FMULP_st(1);
    FADDP_st(1);
    push_fr( R_ECX, (FVm<<2)+3);
    push_fr( R_ECX, (FVn<<2)+3);
    FMULP_st(1);
    FADDP_st(1);
    pop_fr( R_ECX, (FVn<<2)+3);
    JMP_TARGET(doubleprec);
    sh4_x86.tstate = TSTATE_NONE;
:}
FTRV XMTRX, FVn {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    TEST_imm32_r32( FPSCR_PR, R_ECX );
    JNE_rel8( 30, doubleprec );
    load_fr_bank( R_EDX );                 // 3
    ADD_imm8s_r32( FVn<<4, R_EDX );        // 3
    load_xf_bank( R_ECX );                 // 12
    call_func2( sh4_ftrv, R_EDX, R_ECX );  // 12
    JMP_TARGET(doubleprec);
    sh4_x86.tstate = TSTATE_NONE;
:}

FRCHG {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    XOR_imm32_r32( FPSCR_FR, R_ECX );
    store_spreg( R_ECX, R_FPSCR );
    update_fr_bank( R_ECX );
    sh4_x86.tstate = TSTATE_NONE;
:}
FSCHG {:  
    check_fpuen();
    load_spreg( R_ECX, R_FPSCR );
    XOR_imm32_r32( FPSCR_SZ, R_ECX );
    store_spreg( R_ECX, R_FPSCR );
    sh4_x86.tstate = TSTATE_NONE;
:}

/* Processor control instructions */
LDC Rm, SR {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	check_priv();
	load_reg( R_EAX, Rm );
	call_func1( sh4_write_sr, R_EAX );
	sh4_x86.priv_checked = FALSE;
	sh4_x86.fpuen_checked = FALSE;
	sh4_x86.tstate = TSTATE_NONE;
    }
:}
LDC Rm, GBR {: 
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_GBR );
:}
LDC Rm, VBR {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_VBR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC Rm, SSR {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SSR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC Rm, SGR {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SGR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC Rm, SPC {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_SPC );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC Rm, DBR {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_DBR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC Rm, Rn_BANK {:  
    check_priv();
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, REG_OFFSET(r_bank[Rn_BANK]) );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, GBR {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_GBR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, SR {:
    if( sh4_x86.in_delay_slot ) {
	SLOTILLEGAL();
    } else {
	precheck();
	check_priv_no_precheck();
	load_reg( R_EAX, Rm );
	check_ralign32( R_EAX );
	MOV_r32_r32( R_EAX, R_ECX );
	ADD_imm8s_r32( 4, R_EAX );
	store_reg( R_EAX, Rm );
	MEM_READ_LONG( R_ECX, R_EAX );
	call_func1( sh4_write_sr, R_EAX );
	sh4_x86.priv_checked = FALSE;
	sh4_x86.fpuen_checked = FALSE;
	sh4_x86.tstate = TSTATE_NONE;
    }
:}
LDC.L @Rm+, VBR {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_VBR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, SSR {:
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SSR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, SGR {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SGR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, SPC {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_SPC );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, DBR {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_DBR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDC.L @Rm+, Rn_BANK {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_EAX, Rm );
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, REG_OFFSET(r_bank[Rn_BANK]) );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS Rm, FPSCR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_FPSCR );
    update_fr_bank( R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS.L @Rm+, FPSCR {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_FPSCR );
    update_fr_bank( R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS Rm, FPUL {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_FPUL );
:}
LDS.L @Rm+, FPUL {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_FPUL );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS Rm, MACH {: 
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_MACH );
:}
LDS.L @Rm+, MACH {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_MACH );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS Rm, MACL {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_MACL );
:}
LDS.L @Rm+, MACL {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_MACL );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDS Rm, PR {:  
    load_reg( R_EAX, Rm );
    store_spreg( R_EAX, R_PR );
:}
LDS.L @Rm+, PR {:  
    load_reg( R_EAX, Rm );
    precheck();
    check_ralign32( R_EAX );
    MOV_r32_r32( R_EAX, R_ECX );
    ADD_imm8s_r32( 4, R_EAX );
    store_reg( R_EAX, Rm );
    MEM_READ_LONG( R_ECX, R_EAX );
    store_spreg( R_EAX, R_PR );
    sh4_x86.tstate = TSTATE_NONE;
:}
LDTLB {:  :}
OCBI @Rn {:  :}
OCBP @Rn {:  :}
OCBWB @Rn {:  :}
PREF @Rn {:
    load_reg( R_EAX, Rn );
    PUSH_r32( R_EAX );
    AND_imm32_r32( 0xFC000000, R_EAX );
    CMP_imm32_r32( 0xE0000000, R_EAX );
    JNE_rel8(7, end);
    call_func0( sh4_flush_store_queue );
    JMP_TARGET(end);
    ADD_imm8s_r32( 4, R_ESP );
    sh4_x86.tstate = TSTATE_NONE;
:}
SLEEP {: 
    check_priv();
    call_func0( sh4_sleep );
    sh4_x86.tstate = TSTATE_NONE;
    sh4_x86.in_delay_slot = FALSE;
    return 2;
:}
STC SR, Rn {:
    check_priv();
    call_func0(sh4_read_sr);
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC GBR, Rn {:  
    load_spreg( R_EAX, R_GBR );
    store_reg( R_EAX, Rn );
:}
STC VBR, Rn {:  
    check_priv();
    load_spreg( R_EAX, R_VBR );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC SSR, Rn {:  
    check_priv();
    load_spreg( R_EAX, R_SSR );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC SPC, Rn {:  
    check_priv();
    load_spreg( R_EAX, R_SPC );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC SGR, Rn {:  
    check_priv();
    load_spreg( R_EAX, R_SGR );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC DBR, Rn {:  
    check_priv();
    load_spreg( R_EAX, R_DBR );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC Rm_BANK, Rn {:
    check_priv();
    load_spreg( R_EAX, REG_OFFSET(r_bank[Rm_BANK]) );
    store_reg( R_EAX, Rn );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L SR, @-Rn {:
    precheck();
    check_priv_no_precheck();
    call_func0( sh4_read_sr );
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L VBR, @-Rn {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_VBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L SSR, @-Rn {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SSR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L SPC, @-Rn {:
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SPC );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L SGR, @-Rn {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_SGR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L DBR, @-Rn {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_DBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L Rm_BANK, @-Rn {:  
    precheck();
    check_priv_no_precheck();
    load_reg( R_ECX, Rn );
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, REG_OFFSET(r_bank[Rm_BANK]) );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STC.L GBR, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_GBR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STS FPSCR, Rn {:  
    load_spreg( R_EAX, R_FPSCR );
    store_reg( R_EAX, Rn );
:}
STS.L FPSCR, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_FPSCR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STS FPUL, Rn {:  
    load_spreg( R_EAX, R_FPUL );
    store_reg( R_EAX, Rn );
:}
STS.L FPUL, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_FPUL );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STS MACH, Rn {:  
    load_spreg( R_EAX, R_MACH );
    store_reg( R_EAX, Rn );
:}
STS.L MACH, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_MACH );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STS MACL, Rn {:  
    load_spreg( R_EAX, R_MACL );
    store_reg( R_EAX, Rn );
:}
STS.L MACL, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_MACL );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}
STS PR, Rn {:  
    load_spreg( R_EAX, R_PR );
    store_reg( R_EAX, Rn );
:}
STS.L PR, @-Rn {:  
    load_reg( R_ECX, Rn );
    precheck();
    check_walign32( R_ECX );
    ADD_imm8s_r32( -4, R_ECX );
    store_reg( R_ECX, Rn );
    load_spreg( R_EAX, R_PR );
    MEM_WRITE_LONG( R_ECX, R_EAX );
    sh4_x86.tstate = TSTATE_NONE;
:}

NOP {: /* Do nothing. Well, we could emit an 0x90, but what would really be the point? */ :}
%%
    sh4_x86.in_delay_slot = FALSE;
    return 0;
}
